---
layout: page
title: Research
---

I am doing research on deep learing applications for real world problems. In this page, I will share my findings for interesting algorithms.

<ul>
<p> Update for Sep 2021: My current research in ML is derivative-free optimizations method, this is also known as gradient-free optimization. Usually we will use it when gradients of objective functions are unavailable. I found this problem when I tried to use RL to train agents using simulated points, and realized that derivative-free optimizations could be an easier and simpler approach. 
</p>
</ul>

<li><a href="https://arxiv.org/abs/1904.11585" target="_code">this is a good review for DFO if you are also interested</a>
 </li>

<!-- <ul>
<a href="https://github.com/LiCao-Li/Li_Cao/blob/master/files/Resume_work.pdf" target="_blank">this is my CV </a>
</ul> -->


<!-- (files/Resume_work.pdf) 

[Link](./files/Resume_work.pdf) -->
<!-- <div style="padding-top: 5px;border-top: 3px solid #4d7508">

[get the PDF]({{ site.url }}//Resume_work.pdf)
  <p><a href="./quick_start.html"><strong>Quick start</strong></a> is a guide to help with the installation and basic usage of OSHMPI.</p>
  <p style="margin-bottom: 1px"><strong><span style="color: #4d7508;font-size: 13pt">Support and Bug Reporting</span></strong></p>
  
  <div style="padding-top: 5px;border-top: 3px solid #4d7508">
  If you have problems that need any assistance about the OSHMPI installation and usage, or you have found a bug in OSHMPI, please contact <a href="mailto:oshmpi-users@lists.mcs.anl.gov"><strong>oshmpi-users@lists.mcs.anl.gov</strong></a> mailing list. In order to avoid spam, we request you to <a href="https://lists.mcs.anl.gov/mailman/listinfo/oshmpi-users" target="_blank" rel="noopener"><strong>subscribe</strong></a> to this list before sending an email.</div>
</div> -->